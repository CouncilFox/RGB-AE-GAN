{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGB Autoencoder GAN Experiment\n",
    "## Exploring Color Information in Filters\n",
    "### Objective:\n",
    "Investigate how color information propagates into the first convolutional layer of an RGB autoencoder compared to an autoencoder trained on a single channel (Red). Use a discriminator to differentiate between filters of the two encoders and set up a GAN-like training paradigm to fool the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Phase 1: Train RGB and Red Channel Autoencoders**\n",
    "\n",
    "1. **Define Autoencoder Architectures:**\n",
    "   - Basic convolutional autoencoder with `Conv2D` and `Conv2DTranspose` layers.\n",
    "   - One model trained on the RGB input (3D: 256x256x3).\n",
    "   - One model trained on the Red channel (2D: 256x256x1).\n",
    "\n",
    "2. **Data Preparation:**\n",
    "   - Use the CIFAR-10 dataset or another RGB dataset.\n",
    "   - Extract Red channel as a grayscale image for the Red autoencoder.\n",
    "\n",
    "3. **Training:**\n",
    "   - Train both autoencoders separately.\n",
    "   - Use MAE as the loss function and Adam optimizer.\n",
    "\n",
    "4. **Save Filters:**\n",
    "   - Extract and save the filters from the first `Conv2D` layer of each trained autoencoder for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, _), (x_test, _) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Extract Red channel for Red autoencoder\n",
    "x_train_red = x_train[..., 0:1]\n",
    "x_test_red = x_test[..., 0:1]\n",
    "\n",
    "# Autoencoder Model\n",
    "def build_autoencoder(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(np.prod(input_shape), activation='sigmoid')(x)\n",
    "    x = Reshape(input_shape)(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "# Train RGB Autoencoder\n",
    "rgb_autoencoder = build_autoencoder((32, 32, 3))\n",
    "rgb_autoencoder.compile(optimizer='adam', loss='mae')\n",
    "rgb_autoencoder.fit(x_train, x_train, epochs=20, batch_size=128, validation_data=(x_test, x_test))\n",
    "\n",
    "# Train Red Channel Autoencoder\n",
    "red_autoencoder = build_autoencoder((32, 32, 1))\n",
    "red_autoencoder.compile(optimizer='adam', loss='mae')\n",
    "red_autoencoder.fit(x_train_red, x_train_red, epochs=20, batch_size=128, validation_data=(x_test_red, x_test_red))\n",
    "\n",
    "# Extract Filters\n",
    "rgb_filters = rgb_autoencoder.layers[1].get_weights()[0]\n",
    "red_filters = red_autoencoder.layers[1].get_weights()[0]\n",
    "\n",
    "# Save Filters\n",
    "np.save('rgb_filters.npy', rgb_filters)\n",
    "np.save('red_filters.npy', red_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Phase 2: Build and Train the Discriminator**\n",
    "\n",
    "1. **Discriminator Architecture:**\n",
    "   - Input: Flattened filters from the first layer of both autoencoders.\n",
    "   - Layers: A simple feedforward neural network (MLP) with a few dense layers and ReLU activations.\n",
    "   - Output: Binary classification (`RGB` or `R` filter).\n",
    "\n",
    "2. **Dataset Creation:**\n",
    "   - Label the filters: RGB filters as `1` and Red filters as `0`.\n",
    "   - Shuffle and split into training and validation sets.\n",
    "\n",
    "3. **Training:**\n",
    "   - Train the discriminator to classify filters correctly.\n",
    "   - Use binary cross-entropy loss and an Adam optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Filters\n",
    "rgb_filters = np.load('rgb_filters.npy')\n",
    "red_filters = np.load('red_filters.npy')\n",
    "\n",
    "# Prepare Dataset\n",
    "filters = np.concatenate([rgb_filters.reshape(-1, 32 * 32), red_filters.reshape(-1, 32 * 32)])\n",
    "labels = np.array([1] * len(rgb_filters) + [0] * len(red_filters))\n",
    "indices = np.arange(len(labels))\n",
    "np.random.shuffle(indices)\n",
    "filters = filters[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# Split Dataset\n",
    "split_idx = int(0.8 * len(labels))\n",
    "train_filters, val_filters = filters[:split_idx], filters[split_idx:]\n",
    "train_labels, val_labels = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "# Build Discriminator\n",
    "def build_discriminator(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Dense(64, activation='relu')(input_layer)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "discriminator = build_discriminator((32 * 32,))\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "discriminator.fit(train_filters, train_labels, epochs=20, batch_size=64, validation_data=(val_filters, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Phase 3: Set Up GAN Paradigm**\n",
    "\n",
    "1. **Generator Setup:**\n",
    "   - The generator will use the RGB autoencoder and adjust its weights iteratively to fool the discriminator.\n",
    "\n",
    "2. **Training Process:**\n",
    "   - **Step 1:** Freeze the discriminator.\n",
    "   - **Step 2:** Fine-tune the RGB autoencoder’s first convolutional layer to minimize the discriminator's ability to differentiate filters.\n",
    "   - **Step 3:** Alternate training between the discriminator and generator.\n",
    "\n",
    "3. **Loss Functions:**\n",
    "   - Generator loss: Binary cross-entropy from the discriminator’s predictions.\n",
    "   - Discriminator loss: Binary cross-entropy for distinguishing between RGB and Red filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Losses and Training Loop\n",
    "\n",
    "# Freeze Discriminator for GAN training\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Combine Generator and Discriminator\n",
    "gan_input = rgb_autoencoder.input\n",
    "gan_output = discriminator(rgb_autoencoder.layers[1].output)\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n",
    "# GAN Training Loop\n",
    "for epoch in range(20):\n",
    "    # Train Discriminator\n",
    "    discriminator.trainable = True\n",
    "    rgb_preds = discriminator.predict(rgb_filters.reshape(-1, 32 * 32))\n",
    "    red_preds = discriminator.predict(red_filters.reshape(-1, 32 * 32))\n",
    "    d_loss = discriminator.train_on_batch(filters, labels)\n",
    "\n",
    "    # Train Generator\n",
    "    discriminator.trainable = False\n",
    "    g_loss = gan.train_on_batch(x_train, np.ones(len(x_train)))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, D Loss: {d_loss}, G Loss: {g_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "- Visualize filter differences using heatmaps or PCA.\n",
    "- Analyze discriminator accuracy and generator convergence.\n",
    "- Document findings and adjust hyperparameters if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
